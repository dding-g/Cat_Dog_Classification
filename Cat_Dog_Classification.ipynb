{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "last_week_dl_lab_cnn_dogcat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dding-g/Cat_Dog_Classification/blob/master/Cat_Dog_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfvRP8c9oFcn",
        "colab_type": "text"
      },
      "source": [
        "# Dog, cat image classification problem set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bMlMz4EoFco",
        "colab_type": "text"
      },
      "source": [
        "### [CUDA](http://pytorch.org/docs/stable/cuda.html)\n",
        "\n",
        "* cuda를 이용하겠습니다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghm6aX2UoFcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "#train_on_gpu = False\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbfbVWvIoFcs",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Load the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "* 아미지를 다운로드 받습니다\n",
        "* 폴더별로\n",
        " - test\n",
        " - train\n",
        " - validation\n",
        "\n",
        " data를 받습니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-vIYeDvw0X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install googledrivedownloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7_ItD54w8ii",
        "colab_type": "code",
        "outputId": "56e5e06a-eb79-4ac0-afd6-38863f918620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from os.path import exists\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import tarfile \n",
        "\n",
        "#if exists(\"./Cat_Dog_data.tgz\"):\n",
        "#    !rm -rf ./Cat_Dog_data.tgz\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1WpY0qpe7yF5C5M52z1BMIzYVpDYiU3OV',\n",
        "                                   dest_path = './Cat_Dog_data.tgz')\n",
        "\n",
        "tf = tarfile.open(\"Cat_Dog_data.tgz\")\n",
        "tf.extractall()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1WpY0qpe7yF5C5M52z1BMIzYVpDYiU3OV into ./Cat_Dog_data.tgz... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNnl0wVnxvLM",
        "colab_type": "text"
      },
      "source": [
        "## Problem 1 [20 points]: \n",
        "\n",
        "* Training, validation, test를 위한 dataloader, transform을 적절하게 준비해주세요\n",
        "* 아래 data 준비하는 코딩을 수행하고, 아래 markdown에 준비한 과정 및 이유를 구체적으로 설명하세요\n",
        "* 아래 답안 작성에 data의 구조에 대해서 설명하세요\n",
        "* 코드에는 주석을 달아주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiZz3-P3ysrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import helper\n",
        "\n",
        "\n",
        "# 데이터들을 load 할때 적용시키는 transform. 일정한 규격을 만들어줌\n",
        "transform_train_validation = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                                 transforms.RandomResizedCrop(128),\n",
        "                                                 transforms.RandomHorizontalFlip(),\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                                      std=[0.229, 0.224, 0.225])\n",
        "                                                # 정규화\n",
        "                                                # RGB 픽셀들 - mean / std 인데, 학습시킬때 중구난방한 featre들을 응집시켜주는 역할을 한다.\n",
        "                                                # 해당 정규화 값은 RGB image 를 normalize 시키는데 널리 사용되는 값이며\n",
        "                                                # pytorch document에 명시되어 있다.\n",
        "                                                 ])\n",
        "\n",
        "#Test데이터를 위한 transform. Test데이터 이기 때문에 크기만 맞춰주고\n",
        "#다른 변화는 주지 않는다.\n",
        "transform_test = transforms.Compose([\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.RandomResizedCrop(128),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                     ])\n",
        "\n",
        "batch_size = 10\n",
        "base_dir = '/content' # Colab의 base Directory\n",
        "\n",
        "# Train 데이터 load\n",
        "dataset_trainig = datasets.ImageFolder(base_dir + '/train', transform=transform_train_validation)\n",
        "dataloader_training = torch.utils.data.DataLoader(dataset_trainig, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Test 데이터 load\n",
        "dataset_test = datasets.ImageFolder(base_dir + '/test', transform=transform_train_validation)\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size)\n",
        "\n",
        "# Validation 데이터 load\n",
        "dataset_validation = datasets.ImageFolder(base_dir + '/validation', transform=transform_train_validation)\n",
        "dataloader_validation = torch.utils.data.DataLoader(dataset_validation, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Dog, Cat의 class 지정. Test 할때 labeling으로 사용\n",
        "classes = ['dog', 'cat']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Ad2T8wyDJN",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:**\n",
        "===\n",
        "* Train, Validation 은 같은 `Transform`으로 불러온다. \n",
        "\n",
        "* 이때 처음에는 244 x 244, 255 x 255 등 크기를 상대적으로 크게 `resize`해서 불러왔으나, colab의 cuda 메모리 오류 때문에 크기를 128까지 줄였다. dataset이 \n",
        "적지 않으므로 학습에 크게 영향이 없을것이라 생각했다. \n",
        "  * 나중에 안 사실이지만 위의 정규화 값과 함께 널리 쓰이는 `resize` 형식이 244 x 244 라고 한다. [pytorch DOC](https://pytorch.org/docs/stable/torchvision/models.html) 에 나와있다. 여기서는 memory 제한 때문에 크기를 조금 작게 수정했다.\n",
        "\n",
        "* 많은 데이터를 학습시키려면 일반 `GradientDescent`로는 시간이 오래걸리기 때문에 `SGD`를 사용한다. `batch size`를 1000를 주어보았지만 성능이 너무 않좋아져서 20까지 내렸다. \n",
        "\n",
        "* 처음에는 전부 0.5로 정규화 값을 주고 `normalization`를 시켰으나, batch size 조절, layer 수정, epoch 수정 등 많은 노력에도 일정 수치 이하로 떨어지지 않아 image 정규화를 다시 시키는 작업을 했다.\n",
        "  * [pytorch DOC](https://pytorch.org/docs/stable/torchvision/models.html) 에 정규화 값이 나와있는데 이는 pytorch에서 이미지를 정규화 시키는데 널리 사용된다고 한다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4bXK3BxoFdE",
        "colab_type": "text"
      },
      "source": [
        "## Problem 2 [20 point]: Define the Network Architecture\n",
        "\n",
        "* 구현하고자하는 network을 작성해주세요\n",
        "* 아래 구현 방법과 이유를 구체적으로 설명하세요\n",
        "* 코드에는 주석을 달아주세요. \n",
        "* 아래 모델을 구체적으로 설명하고, 설정 이유를 작성해주세요\n",
        "* 본 과정에서는 직접 network을 구현하고, transfer learning은 활용하지 않도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaNxUAd4oFdF",
        "colab_type": "code",
        "outputId": "fd07deac-af4e-4595-db46-43db21265907",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "#@title 기본 제목 텍스트\n",
        "# 코드 작성\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "   # 레이어 정의\n",
        "    def __init__(self):  \n",
        "        super(Net, self).__init__()\n",
        "        # input shape : 128 x 128 x 3\n",
        "        # conv1 filter : 7 x 7, input chanel size : 3\n",
        "        # Conv2d(input chanal size, filter chanel size, filter size, padding)\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)# 결과 size : 128 x 128 x 16\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1) # 결과 size : 128 x 128 x 32\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1) # 결과 size : 128 x 128 x 64\n",
        "\n",
        "        # conv1 -> pool -> conv2 -> pool -> conv3 -> pool\n",
        "        #pool 때문에 해상도를 절반으로 줄임. \n",
        "        #128 X 128    64 x 64    32 x 32    16 x 16(최종 size)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2,2) # 해상도를 절반으로 줄이는 작업. 연산량 줄이기 위함\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 128, 256 * 32)\n",
        "        self.fc2 = nn.Linear(256 * 32, 2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        x = x.view(-1, 256 * 128) #vector를 펴는 작업\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.log_softmax(self.fc2(x), dim = 1)\n",
        "        return x \n",
        "\n",
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=32768, out_features=8192, bias=True)\n",
            "  (fc2): Linear(in_features=8192, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkP09gUJzKVc",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:**\n",
        "===\n",
        "* Conv layer를 3 곂으로 쌓고 커널 사이즈는 3x3, stride = 1, padding = 1 그리고 채널 수는 두배씩 늘려갔다. \n",
        "* filter size는 3과 7중 어느것이 더 성는이 좋은가를 보기위해 실험했는데 크게 성능차이가 나지는 않았다. \n",
        "* size를 계산하기 쉽도록 padding 을 조절하고 높은 해상도로는 연산량이 많아지므로 pool로 크기를 2배씩 줄인다. \n",
        "* overfitting을 방지하기위해 dropout을 주었으며 full connected 후에 softmax 함수를 씌워 확률값을 알 수 있도록 하였다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xukdFNh3oFdH",
        "colab_type": "text"
      },
      "source": [
        "## Problem 3 [5 point]: Specify Loss Function\n",
        "\n",
        "* Loss 함수와 optimizer를 구현하세요\n",
        "* 선정 이유를 설명하세요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuczyoY5oFdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 코드\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.008)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64psu2RjzdrZ",
        "colab_type": "text"
      },
      "source": [
        " **설명:**\n",
        " ===\n",
        "\n",
        " * `SGD`는 `batch size`를 1로 주는 `GD`와 달리 `batch size`를 크게 주어 탐색 속도를 늘린다. 렌덤하게 데이터 값을 받아오고 해당 데이터를 가지고 최적의 해(weight)를 찾기 때문에 `batch size`보다는 정확도가 낮을 수 있지만, 빠르게 학습할 수 있다는 장점이 있다. 따라서 20,000개의 데이터를 학습시키기에 `batch size`를 1로 주는건 너무 가혹하다고 생각해 `SGD`를 채택하였다.\n",
        " \n",
        " * 우리는 Dog, Cat 2가지 Class 중 하나를 예측하는 일을 원한다. 따라서 Class 분류에 특화되어 있는 `Cross-entropy` loss function을 사용하겠다. 내가 학습한 결과와 input으로 들어오는 값을 곱해 loss를 계산하고 이 과정에서 `Gradient`를 구해 최적 `weight`를 구하는데 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcIVfJz9oFdJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Problem 4 [30 point]: Train the Network\n",
        "\n",
        "* training loss와 validation loss를 기록하며 training을 구현하세요\n",
        "* 만약 validation loss가 최소화된 모델을 저장하세요\n",
        "* 코드에는 모두 주석을 포함해주세요\n",
        "* training과정을 설명하고, training 결과를 분석해주세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fjBJWFIboFdJ",
        "colab_type": "code",
        "outputId": "6dba2fd0-2ed7-4676-840c-2afc6abb4396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 코드 작성\n",
        " \n",
        "# 반복 횟수 지정\n",
        "n_epochs = 60\n",
        "\n",
        "valid_loss_min = np.Inf # valid_loss값의 최소 값을 지정\n",
        "\n",
        "# epoch 만큼 반복\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # train_loss와 valid_loss를 미리 init\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    # batch size 만큼 data를 load하기 때문에 batch size만큼 반복\n",
        "    for data, target in dataloader_training: \n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        # 학습했던 gradient를 초기화하고 새로 학습할 준비를 함\n",
        "        optimizer.zero_grad()\n",
        "        # 현재 불러온 image를 기반으로 forward를 호출함. CNN 학습\n",
        "        output = model(data)\n",
        "        # 학습이 끝난 후 계산 결과와 현재 불러온 image의 label(0 or 1)을 이용해 loss를 계산.\n",
        "        loss = criterion(output, target)\n",
        "        # loss 값들을 이용해 Gradient 계산\n",
        "        loss.backward()\n",
        "        # hyper parameter들을 update한다.\n",
        "        optimizer.step()\n",
        "        # training loss 값을 update 한다.\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    validation_iter = iter(dataloader_validation)\n",
        "    for data, target in validation_iter:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # 현재 불러온 image를 기반으로 forward를 호출함. CNN 학습\n",
        "        output = model(data)\n",
        "        # 학습이 끝난 후 계산 결과와 현재 불러온 image의 label(0 or 1)을 이용해 loss를 계산.\n",
        "        loss = criterion(output, target)\n",
        "        # validation loss 값을 update 한다.\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # Trainloss 와 Validation loss의 평균을 구함\n",
        "    train_loss = train_loss/len(dataloader_training.sampler)\n",
        "    valid_loss = valid_loss/len(dataloader_validation.sampler)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar3_ir0001.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.664063 \tValidation Loss: 0.639547\n",
            "Validation loss decreased (inf --> 0.639547).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.628244 \tValidation Loss: 0.601568\n",
            "Validation loss decreased (0.639547 --> 0.601568).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.601969 \tValidation Loss: 0.583861\n",
            "Validation loss decreased (0.601568 --> 0.583861).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.584682 \tValidation Loss: 0.552799\n",
            "Validation loss decreased (0.583861 --> 0.552799).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.569176 \tValidation Loss: 0.560006\n",
            "Epoch: 6 \tTraining Loss: 0.556928 \tValidation Loss: 0.571247\n",
            "Epoch: 7 \tTraining Loss: 0.546492 \tValidation Loss: 0.542372\n",
            "Validation loss decreased (0.552799 --> 0.542372).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.538259 \tValidation Loss: 0.527349\n",
            "Validation loss decreased (0.542372 --> 0.527349).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.527392 \tValidation Loss: 0.504275\n",
            "Validation loss decreased (0.527349 --> 0.504275).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.520661 \tValidation Loss: 0.517116\n",
            "Epoch: 11 \tTraining Loss: 0.513816 \tValidation Loss: 0.501816\n",
            "Validation loss decreased (0.504275 --> 0.501816).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.507871 \tValidation Loss: 0.488478\n",
            "Validation loss decreased (0.501816 --> 0.488478).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.497879 \tValidation Loss: 0.475973\n",
            "Validation loss decreased (0.488478 --> 0.475973).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 0.493330 \tValidation Loss: 0.497210\n",
            "Epoch: 15 \tTraining Loss: 0.478097 \tValidation Loss: 0.444580\n",
            "Validation loss decreased (0.475973 --> 0.444580).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 0.475170 \tValidation Loss: 0.465332\n",
            "Epoch: 17 \tTraining Loss: 0.474898 \tValidation Loss: 0.469047\n",
            "Epoch: 18 \tTraining Loss: 0.462417 \tValidation Loss: 0.449720\n",
            "Epoch: 19 \tTraining Loss: 0.454768 \tValidation Loss: 0.486592\n",
            "Epoch: 20 \tTraining Loss: 0.448149 \tValidation Loss: 0.441384\n",
            "Validation loss decreased (0.444580 --> 0.441384).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 0.447371 \tValidation Loss: 0.408895\n",
            "Validation loss decreased (0.441384 --> 0.408895).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 0.441390 \tValidation Loss: 0.432821\n",
            "Epoch: 23 \tTraining Loss: 0.433815 \tValidation Loss: 0.409901\n",
            "Epoch: 24 \tTraining Loss: 0.430778 \tValidation Loss: 0.425356\n",
            "Epoch: 25 \tTraining Loss: 0.423604 \tValidation Loss: 0.420630\n",
            "Epoch: 26 \tTraining Loss: 0.417218 \tValidation Loss: 0.393962\n",
            "Validation loss decreased (0.408895 --> 0.393962).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 0.414148 \tValidation Loss: 0.396890\n",
            "Epoch: 28 \tTraining Loss: 0.405227 \tValidation Loss: 0.425229\n",
            "Epoch: 29 \tTraining Loss: 0.406302 \tValidation Loss: 0.384787\n",
            "Validation loss decreased (0.393962 --> 0.384787).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 0.396434 \tValidation Loss: 0.369239\n",
            "Validation loss decreased (0.384787 --> 0.369239).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 0.391066 \tValidation Loss: 0.365322\n",
            "Validation loss decreased (0.369239 --> 0.365322).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 0.387476 \tValidation Loss: 0.371032\n",
            "Epoch: 33 \tTraining Loss: 0.386758 \tValidation Loss: 0.369991\n",
            "Epoch: 34 \tTraining Loss: 0.386133 \tValidation Loss: 0.399888\n",
            "Epoch: 35 \tTraining Loss: 0.373404 \tValidation Loss: 0.357802\n",
            "Validation loss decreased (0.365322 --> 0.357802).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 0.376781 \tValidation Loss: 0.378105\n",
            "Epoch: 37 \tTraining Loss: 0.367737 \tValidation Loss: 0.366678\n",
            "Epoch: 38 \tTraining Loss: 0.365469 \tValidation Loss: 0.397010\n",
            "Epoch: 39 \tTraining Loss: 0.361894 \tValidation Loss: 0.380071\n",
            "Epoch: 40 \tTraining Loss: 0.357158 \tValidation Loss: 0.346045\n",
            "Validation loss decreased (0.357802 --> 0.346045).  Saving model ...\n",
            "Epoch: 41 \tTraining Loss: 0.351454 \tValidation Loss: 0.347667\n",
            "Epoch: 42 \tTraining Loss: 0.349202 \tValidation Loss: 0.363437\n",
            "Epoch: 43 \tTraining Loss: 0.346031 \tValidation Loss: 0.319765\n",
            "Validation loss decreased (0.346045 --> 0.319765).  Saving model ...\n",
            "Epoch: 44 \tTraining Loss: 0.346992 \tValidation Loss: 0.326848\n",
            "Epoch: 45 \tTraining Loss: 0.347612 \tValidation Loss: 0.368715\n",
            "Epoch: 46 \tTraining Loss: 0.341790 \tValidation Loss: 0.323196\n",
            "Epoch: 47 \tTraining Loss: 0.341671 \tValidation Loss: 0.303330\n",
            "Validation loss decreased (0.319765 --> 0.303330).  Saving model ...\n",
            "Epoch: 48 \tTraining Loss: 0.329174 \tValidation Loss: 0.326971\n",
            "Epoch: 49 \tTraining Loss: 0.332176 \tValidation Loss: 0.304509\n",
            "Epoch: 50 \tTraining Loss: 0.326662 \tValidation Loss: 0.306177\n",
            "Epoch: 51 \tTraining Loss: 0.322797 \tValidation Loss: 0.325929\n",
            "Epoch: 52 \tTraining Loss: 0.324224 \tValidation Loss: 0.302481\n",
            "Validation loss decreased (0.303330 --> 0.302481).  Saving model ...\n",
            "Epoch: 53 \tTraining Loss: 0.321601 \tValidation Loss: 0.292642\n",
            "Validation loss decreased (0.302481 --> 0.292642).  Saving model ...\n",
            "Epoch: 54 \tTraining Loss: 0.317102 \tValidation Loss: 0.304229\n",
            "Epoch: 55 \tTraining Loss: 0.323442 \tValidation Loss: 0.310493\n",
            "Epoch: 56 \tTraining Loss: 0.317214 \tValidation Loss: 0.302299\n",
            "Epoch: 57 \tTraining Loss: 0.313159 \tValidation Loss: 0.290535\n",
            "Validation loss decreased (0.292642 --> 0.290535).  Saving model ...\n",
            "Epoch: 58 \tTraining Loss: 0.313271 \tValidation Loss: 0.280420\n",
            "Validation loss decreased (0.290535 --> 0.280420).  Saving model ...\n",
            "Epoch: 59 \tTraining Loss: 0.308158 \tValidation Loss: 0.289863\n",
            "Epoch: 60 \tTraining Loss: 0.306719 \tValidation Loss: 0.287370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkF7i-6Y0EAF",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:**\n",
        "==\n",
        "\n",
        "* ephoc 만큼 반복하며 학습한다. \n",
        "  - 1회 학습마다 loss를 batch size 만큼 데이터를 불러와 학습시킨다. \n",
        "  - 이때 loss는 학습이 끝난 `output` 데이터와 현재 이미지로 불러와 있는 `target(label)`을 이용해 `Cross entropy` 방식으로 loss를 갱신한다.\n",
        "* validation도 마찬가지로 batch size만킄 데이터를 불러오고, 불러온 데이터들을 학습이 끝난 `output`데이터들과 `validation` 데이터들을 이용해 loss를 갱신한다. 이렇게 되면 해당 image에 대해 학습한 결과, 테스트한 결과를 동시에 알 수 있으므로 테스트의 진행방향이 어떤지 사용자가 추측할수있다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqX__Ju3oFdL",
        "colab_type": "text"
      },
      "source": [
        "## Problem 5 [5 point] Validation Loss가 최소화된 Model가져오기\n",
        "\n",
        "* 최소 validation loss를 갖는 model을 불러옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LF9TzTWoFdM",
        "colab_type": "code",
        "outputId": "4f4cdd59-9daf-4093-c567-53a7d13ef44f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 코드 작성\n",
        "model.load_state_dict(torch.load('model_cifar3_ir0001.pt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLg9vQC2oFdR",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Problem 6 [20point]: Test the Trained Network\n",
        "\n",
        "* Test set을 활용하여 성능 검증\n",
        "* Accuracy (분류 성공률)와 test loss를 출력하세요\n",
        "* 코드에는 주석을 달아주세요\n",
        "* 아래 test 결과에 대해서 간단하게 설명/분석 해주세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh_Pu57ToFdR",
        "colab_type": "code",
        "outputId": "e1d6ed7a-7ca8-40e3-fe72-f31e8d76f207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# 코드 작성\n",
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "for data, target in dataloader_test:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(dataloader_test.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(2):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.287689\n",
            "\n",
            "Test Accuracy of   dog: 90% (1128/1250)\n",
            "Test Accuracy of   cat: 84% (1057/1250)\n",
            "\n",
            "Test Accuracy (Overall): 87% (2185/2500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywjwrJ691eL_",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:**\n",
        "==\n",
        "* Test데이터를 가지고 위의 학습을 통해 weight를 잘 찾았는지 알아본다. \n",
        " - 위에서 했던 방식과 똑같이 데이터를 불러오고, 학습한 데이터와 test tartget(label)을 이용해 `Cross entropy`방식으로 loss를 갱신한다.\n",
        " - 데이터들이 얼마나 잘 맞았는지 알아보는 Accuracy를 계산하기 위해 학습한 `outout`과 입력받은 `target`의 label을 비교해, 예측을 성공한 케이스의 수와 전체 수를 구해 저장 및 연산한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkhG9np03CEm",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Problem 7: 전체적인 총평\n",
        "\n",
        "* Data준비, Training과 validation 과정에서 성능 개선을 위해서 수행한 과정과 성공/실패 이유를 분석해주세요\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCr5fHLi3UIQ",
        "colab_type": "text"
      },
      "source": [
        "**설명:**\n",
        "==\n",
        "1. 데이터 준비\n",
        "  * 훈련의 다양화를 위해 `location, RandomResize, RandomHorizonCrop`들을 적용시켰다.\n",
        "  * 연산의 부담을 덜기위해 이미지를 resize 할때 128 x 128 로 비교적 작게 주었다. 사진을 실제로 뽑아보니 10개중 7개 정도 비율로 얼굴이 잘 나와있는걸 볼 수 있었다.\n",
        "  * batch size는 처음에 200, 500, 1000 등 상당히 크게 주었다. `SGD`의 특성상 큰 `Batch size`를 주어도 된다는 생각이었는데 이는 우리의 모델이 잘 구성되었을때 통용하는 이야기 였다. loss값이 점점 커지는걸 보고 최대한 모델을 잘 만들어 보고 `Batch size`는 조금 작게 주었다.\n",
        "  ---\n",
        "2. 학습\n",
        "* epoch를 60회 정도로 주고 학습시켜서 기록을 보고 괜찮은 epoch이 어느정도인지 파악한다.\n",
        "* 처음에는 ConvLayer를 5 ~ 6 곂으로 쌓아 채널 수를 늘려보고, `full connected`할때 사용되는 `nn.Linear`의 parameter들을 조정해보기도 했다.  `Cuda OutofMemory Error`와 별로 개선되지 않는 loss를 보고 다른 방법을 찾았다.\n",
        "* 가장 효과적인 방법은 `Normalization`을 제대로 해 주는 것 이다. 위에서도 말했듯이 RGB image를 `Normalization`할때 널리 사용되는 `mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]` 값으로 바꾸어 주었다. 원래는 0.5 로 `Normalization` 해주었는데, 생각해보니 이는 흑백 사진. 즉 값의 분포에 대한 변수가 없는 이진 데이터에 대해서만 효과가 있다.\n",
        "* 다음은 `batch size`를 조절했다. 기존의 100회 이상의 size에서 30,20,10 으로 점차 내렸다. `BGD`와 `SGD`의 특성을 생각해 정확도를 높이기 위해 size를 줄였다.\n",
        "* `batch size`가 20인 경우\n",
        " - test accuracy가 dog : 88%, cat : 80%, total : 84% / training loss : 0.253, validation loss : 0.254 가 나왔다. \n",
        "* `batch size`가 10인 경우\n",
        " - test accuracy가 dog : 90%, cat : 86%, total : 88% 가 나왔다.\n",
        "* learning rate을 0.01로 두고 60회 epoch를 돌려 loss를 0.25 까지 떨구었다.\n",
        " + 더 떨구기 위해 조금 더 촘촘한 작업이 필요하다고 생각했다. 그래서 SGD의 Iearning rate 을 0.01 -> 0.001로 낮춰 gradient를 더 촘촘하게 찾을 수 있도록 하였다. 하지만 \n",
        "loss가 떨어지는 속도는 너무 느렸고 충분한 성능을 낼 수 없었다. 2만개의 데이터를 Iearning rate  0.001로 학슴시키기엔 충분한 epoch를 낼 수 없어서(학습 속도가 너무 느려서 많이 줄 수 없었다.) Ir을 0.008 정도로 주고 학습을 다시 시켜 보았다.\n",
        "* Iearning rate을 0.008로 준 경우\n",
        "  - test accuracy가 dog : 87%, cat : 89%, total : 88% 가 나왔다.\n",
        "  - epoch를 더 주고 학습을 시키면 더 좋은 성능을 낼 것 같았지만 이정도로만 학습시켜도 5시간정도 걸려서 더 늘리는건 힘들것같다.\n",
        "  - 성능 차이를 보기위해 7x7 사이즈로 주었던 filter size를 3x3으로 바꾸었다. 결과는 dog : 90%, cat : 84%, total : 87% 로 큰 차이는 없는것으로 보였다.\n",
        "\n",
        "  ---\n",
        "3. 결과\n",
        "\n",
        "* 결과는 강아지 분류 90%, 고양이 분류 84%로 그닥 좋지 않은 성능을 보였다. 정확도를 더 올리기 위해서는 epoch을 좀더 늘리고 model을 Conv Layer를 추가하거나, image resize를 좀 크게 해주거나 하는 방식으로 최대한 효과적으로 구성해야 하는데, 메모리 등 제한적인 환경에서 진행하다 보니 Layer의 크기, image의 크기 등 더 많은 시도를 하지 못해 아쉽다."
      ]
    }
  ]
}